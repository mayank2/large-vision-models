{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt  # Import the matplotlib library for image visualization\n",
    "import json\n",
    "\n",
    "# Check if CUDA (GPU) is available, otherwise use CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CLIP model and preprocessing pipeline\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of clothing items for comparison\n",
    "objects = [\"airplane\", \"boat\", \"car\", \"bike\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = 'rsicd/annotations.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to test data\n",
    "f = open(json_path)\n",
    "data = json.load(f)\n",
    "input_data = data['images']\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the input data you want to analyze\n",
    "index_ = 0\n",
    "\n",
    "# Assuming 'input_data' is a list of JSON-like objects with image information\n",
    "image_json = input_data[index_]\n",
    "\n",
    "# Construct the full path to the image file using the given 'image_path'\n",
    "image_path = os.path.join(\"rsicd/images/\", image_json['filename'])\n",
    "\n",
    "# Get the class label of the image\n",
    "# image_class = image_json['class_label']\n",
    "\n",
    "# Preprocess the image and move it to the appropriate device (CPU or GPU)\n",
    "image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "\n",
    "# Tokenize and move the clothing item names to the appropriate device\n",
    "text = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in objects]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    # Encode image and text\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    \n",
    "    # Calculate similarity scores between image and text\n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarity scores\n",
    "similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "values, indices = similarity[0].topk(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top predictions:\n",
      "\n",
      "        airplane: 99.61%\n",
      "             car: 0.32%\n",
      "            bike: 0.04%\n",
      "            boat: 0.02%\n"
     ]
    }
   ],
   "source": [
    "# Print the top predictions\n",
    "print(\"\\nTop predictions:\\n\")\n",
    "for value, index in zip(values, indices):\n",
    "    print(f\"{objects[index]:>16s}: {100 * value.item():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai_diff",
   "language": "python",
   "name": "fastai_diff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
